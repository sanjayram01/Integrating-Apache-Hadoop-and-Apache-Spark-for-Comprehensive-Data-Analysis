# Integrating-Apache-Hadoop-and-Apache-Spark-for-ComprehensiveData-Analysis
A data analysis project involving customer segmentation using PySpark and Hadoop. This project is configured to run Spark in standalone mode.

## Project Structure






## Setup

1. Clone the Repository:

   ```sh
   git clone <repository_url>
   cd Big_Data_Project

2. Install Dependencies:

Ensure you have Python 3.7+ and pip installed.

```
pip install -r requirements.txt
```
