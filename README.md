# Integrating-Apache-Hadoop-and-Apache-Spark-for-ComprehensiveData-Analysis
A data analysis project involving customer segmentation using PySpark and Hadoop. This project is configured to run Spark in standalone mode.

## Project Structure

Big_Data_Project/
│
├── data/
│ ├── fname=0.csv
│ ├── fname=1.csv
│ ├── fname=2.csv
│ ├── fname=3.csv
│ ├── temp_H.txt
│ ├── missing_values_plot.png
│ ├── Frequency_log_plot.png
│ ├── Frequency_plot.png
│ ├── Monetary_histogram.png
│ ├── Monetary_log_histogram.png
│ ├── Monetary_log_plot.png
│ ├── Monetary_plot.png
│ ├── Recency_Boxcox_histogram.png
│ ├── Recency_Boxcox_plot.png
│ ├── Recency_histogram.png
│ └── Recency_plot.png
│
├── scripts/
│ ├── Big_Data_Project.ipynb
│ └── Utility_Folder/
│ ├── utility.py
│ └── init.py
│
└── README.md




## Setup

1. Clone the Repository:

   ```sh
   git clone <repository_url>
   cd Big_Data_Project

2. Install Dependencies:

Ensure you have Python 3.7+ and pip installed.

```
pip install -r requirements.txt
```

3.Run the Jupyter Notebook:

To explore the analysis interactively, run the Jupyter notebook.
